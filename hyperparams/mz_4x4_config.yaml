PER:
    value: true
PER_alpha:
    value: 0.5
PUCT_C:
    value: 2.5
PUCT_variant:
    value: visit
action_selection:
    value: visit
action_space:
    value:
        - 0
        - 1
        - 2
batch_size:
    value: 128
blocks:
    value: 3
channels:
    value: 12
checkpoint_interval:
    value: 10
conv_layers_trans:
    value:
        - - 32
          - 1
          - 1
        - - 64
          - 1
          - 1
cum_reward:
    value: false
custom_map:
    value: 4x4_3h_3d
debug_mode:
    value: false
discount:
    value: 0.997
downsample:
    value: null
encoding_loss_weight:
    value: null
encoding_size:
    value: 8
expansion_budget:
    value: 13
expansion_strategy:
    value: null
fc_dynamics_layers:
    value:
        - 32
fc_layers_trans:
    value:
        - 128
        - 64
fc_policy_layers:
    value:
        - 32
fc_representation_layers:
    value:
        - 32
fc_reward_layers:
    value:
        - 32
fc_value_layers:
    value:
        - 32
game_name:
    value: custom_grid
get_fast_predictions:
    value: true
logger:
    value: wandb
loss_weight_decay:
    value: null
lr_decay_rate:
    value: 0.95
lr_decay_steps:
    value: 2000
lr_init:
    value: 0.015
max_moves:
    value: 18
max_num_gpus:
    value: null
max_seq_length:
    value: 25
max_time_minutes:
    value: null
mlp_head_layers:
    value:
        - 32
        - 16
momentum:
    value: 0.9
muzero_player:
    value: 0
mvc_beta:
    value: 0.3
mvc_softmax_temps:
    value: null
negative_reward:
    value: -0
network:
    value: resnet
norm_layer:
    value: true
num_simulations:
    value: 25
num_unroll_steps:
    value: 10
num_workers:
    value: 2
observation_shape:
    value:
        - 6
        - 4
        - 4
obstacle:
    value: lava
opponent:
    value: null
optimizer:
    value: Adam
pb_c_base:
    value: 19652
pb_c_init:
    value: 1.25
players:
    value:
        - 0
policy_target_type:
    value: visit
positional_embedding_type:
    value: sinus
pov:
    value: 1_hot_god
predict_reward:
    value: true
random_map:
    value: true
ratio:
    value: null
reanalyse_on_gpu:
    value: true
reduced_channels_policy:
    value: 4
reduced_channels_reward:
    value: 4
reduced_channels_value:
    value: 4
replay_buffer_size:
    value: 150000
representation_network_type:
    value: res
resnet_fc_policy_layers:
    value:
        - 16
resnet_fc_reward_layers:
    value:
        - 16
resnet_fc_value_layers:
    value:
        - 16
root:
    value: /kaggle/working/TransZero
root_dirichlet_alpha:
    value: 0.3
root_exploration_fraction:
    value: 0.3
save_interval:
    value: 5000
save_model:
    value: true
self_play_delay:
    value: 0
self_prob_type:
    value: visit
selfplay_on_gpu:
    value: true
show_preds:
    value: false
softmax_limits:
    value:
        - 0.25
        - 0.5
        - 1
softmax_temps:
    value:
        - 1
        - 0.5
        - 0.25
stable_transformer:
    value: false
stacked_observations:
    value: 0
start_dir:
    value: null
start_pos:
    value: null
state_size:
    value: null
stopping_criterion:
    value: num_played_steps
support_size:
    value: 10
td_steps:
    value: 20
temperature_threshold:
    value: null
test_ucb:
    value: false
testing:
    value: false
train_on_gpu:
    value: true
training_delay:
    value: 0
training_steps:
    value: 100000
transformer_heads:
    value: 8
transformer_hidden_size:
    value: 32
transformer_layers:
    value: 4
use_forward_causal_mask:
    value: true
use_last_model_value:
    value: true
use_proj:
    value: false
value_loss_weight:
    value: 0.5
warmup_steps:
    value: 625
weight_decay:
    value: 0.0001
